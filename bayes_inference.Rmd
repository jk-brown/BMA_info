---
title: "bayes_inference_basic"
author: "Joe Brown"
date: "2023-04-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Goal:

The goal here is to use basic Bayesian inference to compute weights for model iterations using observed data. 

I am using some pre-saved Hector data as an example. I use existing `matilda` functions when possible and write new functions when needed. 

I present the functions in steps and complete with how the functions are integrated.

Producing Hector data:
```{r, message=FALSE}
library(matilda)
# build example data frame from Hector ssp 245 core
core <- newcore(system.file("input/hector_ssp245.ini", package = "hector"))

# set seed and generate params
set.seed(123)
params <- generate_params(core, 10)

start <- Sys.time()
# run hector - results save years and vars in the obs data for now
h_result <- iterate_hector(core, params, save_years = 1959:2021, save_vars = CONCENTRATIONS_CO2())
print(Sys.time()-start)

# adding in a run_zero; run with values that match obs
run_zero <- data.frame(scenario = h_result$scenario,
                       year = criterion_co2_obs()$years,
                       variable = h_result$variable,
                       value = criterion_co2_obs()$obs_values,
                       units = h_result$units,
                       run_number = 0)

# add run_zero to the dataframe
h_result <- rbind(h_result, run_zero)

```

The following function is used to compute the RMSE of the modeled data against the observed data. This is the average difference between predicted and obs values. It is a useful measure for evaluating the accuracy of models.

```{r}
# function to compute RMSE values
# x = predicted data
# y = observed data

RMSE_calc <- function(x, y) {
  
  # compute RMSE
  rmse_vals = sqrt(mean((x - y)^2))
  
  # return a vector of RMSE values
  return(rmse_vals)
  
}
```

There are `R` functions that compute RMSE, but it would require importing another package, and it is easy enough to write our own function.

____

For the next chunk of code, I give piecewise explanations without evaluating, then combine it into one Bayesian weighting function. We want the weighting function to take a df of subsetted model data that matches the scoring criterion of interest -- this takes place in `score_hruns`.

The first step is to take the input data frame, split it by `run_number` and apply `RMSE_apply` to model, and bind the results.

```{r, eval=FALSE}
# Function to compute bayes_wts
# x = merged df that is produced in score_hruns

bayes_wts <- function(x) {
  
  # split the x data frame by model run_number 
  split_list = split(x, x$run_number)
  
  # for each of the dfs in the split_list compute RMSE using model predicted 
  # data and obs_data  
  rmse_vals = lapply(split_list, function(df) {
    RMSE_calc(x = df$value, y = df$value_obs)
  })
  
  # rbind the rmse_vals - makes it easier to complete subsequent steps
  rmse_bind <- do.call(rbind, rmse_vals)
  
```

Once we have RMSE values computed for the df, we can use them to compute a likelihood function. This likelihood function will eventually be used to compute posterior probabilities. 

```{r, eval=FALSE}
 # Compute likelihood using normal distribution likelihood function.
  # This is the probability of observing the modeled data given the 
  # observed data.
  
likelihood = exp(-0.5 * (rmse_bind) ^ 2)

```

This is a normal distribution likelihood function. The RMSE values in `rmse_bind` represent the deviations of predicted values from observed values. This formula assumes the errors (RMSE values) follow a normal distribution.

This formula is a modified version of the likelihood function used in Massoud et al. 2020, who use BMA weights (where we use RMSE).

The `-0.5` is a constant that appears in the density function of a normal distribution. This will produce a negative value (`-0.5 * (rmse_bind) ^ 2`). 

The purpose of `exp()` is to transform the negative term into a positive term between 1-0 that can be interpreted as a likelihood, which should be proportional to a probability. 

Example:

RMSE = 0.0 (perfect fit - high likelihood of predicting observed data)

`-0.5 * 0^2 = 0`

`exp(0) = 1`

RMSE = 0.5 (relatively good fit - high likelihood of predicting observed data)

`-0.5 * 0.5^2 = -0.125`

`exp(-0.125) = 0.88`

When we have likelihood values (under our given assumptions), we can use it to compute unnormalized posterior values. This is the posterior scores when we incorporate prior knowledge of the model distribution.

```{r, eval=FALSE}
 # Computing unnormalized posterior scores 
  # Currently only computing posterior scores using uniform prior.
  # uniform prior is calculated as 1/length(likelihood) which is 
  # the same as 1 / # of runs.
  
  posterior = likelihood * (1 / length(likelihood))

```

Currently the prior is uniform based on the number of runs. For now the prior is uniform (ex. 1/10). Prior is based on the number of runs because this function will be integrated within another function. If a separated vector is being used it would take the form of `prior = 1/length(x)`.

It might be better if we compute a marginal likelihood -- haven't looked into this in depth, but think this paper will have some useful information -- https://doi.org/10.1093/biomet/asz077.

With these posterior values, we can compute normalized posterior probabilities:

```{r, eval=FALSE}
 # Computes posterior probabilities - normalized posterior weights. 
  # Will sum to 1 and there for get significantly smaller as number 
  # of runs increases.
  posterior_probs = posterior / sum(posterior)
  
  # Create data frame of results - get run_numbers from the list where RMSE values
  # are computed (names of the split_list components)
  bayes_wts_result <- data.frame(RMSE = rmse_bind,
                                 posterior_vals = posterior,
                                 posterior_prob = posterior_probs,
                                 run_number = names(rmse_vals))
  
  return(bayes_wts_result)
```

The full `bayes_wts` function looks like this:
```{r}
# Function to compute bayes_wts
# x = merged df that is produced in score_hruns

bayes_wts <- function(x, e = 2) {
  
  print(e)
  
  # split the x data frame by model run_number 
  split_list = split(x, x$run_number)
  
  # for each of the dfs in the split_list compute RMSE using model predicted 
  # data and obs_data  
  rmse_vals = lapply(split_list, function(df) {
    RMSE_calc(x = df$value, y = df$value_obs)
  })
  
  # rbind the rmse_vals - makes it easier to complete subsequent steps
  rmse_bind <- do.call(rbind, rmse_vals)
  
  # Compute likelihood using normal distribution likelihood function.
  # This is the probability of observing the modeled data given the 
  # observed data.
  likelihood = exp(-0.5 * (rmse_bind) ^ e)
  
  # Computing unnormalized posterior scores 
  # Currently only computing posterior scores using uniform prior.
  # uniform prior is calculated as 1/length(likelihood) which is 
  # the same as 1 / # of runs.
  posterior = likelihood * (1 / length(likelihood))
  
  # Computes posterior probabilities - normalized posterior weights. 
  # Will sum to 1 and there for get significantly smaller as number 
  # of runs increases.
  posterior_probs = posterior / sum(posterior)
  
  # Create data frame of results - get run_numbers from the list where RMSE values
  # are computed (names of the split_list components)
  bayes_wts_result <- data.frame(RMSE = rmse_bind,
                                 posterior_vals = posterior,
                                 posterior_prob = posterior_probs,
                                 run_number = names(rmse_vals))
  
  return(bayes_wts_result)
}

```

I added an argument to the function called `e` - this is to test out the impact of altering the likelihood function decay.

and can be used as the `score_function` in `score_hruns`:

```{r}
# x = df of iterate_hector result, here = h_dat
# criterion = criterion used for scoring, here = crit (a df read-in above)
# scoring_function = function used to produce wts 
score_hruns_ed <- function(x, criterion, score_function, e,...) {

  # subset to include years for CO2 screening
  x_subset <- subset(x, x$year %in% criterion$years & x$variable == criterion$var)

  # creates observed data frame
  obs_dat <- data.frame(year = criterion$year, value_obs = criterion$obs_values)

  # merge hector results with calibration data observed CO2 data
  x_merge <- merge(x_subset, obs_dat, by = 'year')

  # use x_merge as input for `bayes_wts` -> score_function, return values  
  return(score_function(x_merge, e = e))
  
}

```

Here, `score_hruns` is edited because: 

1.  We are using an imported data frame rather than a criterion (which is the workflow in `matilda`). To avoid errors I removed the error messages.

2. `bayes_post` produces single values based on the distributions of the residuals, rather than a mean of absolute differences for each individual data point (final piece of `score_hruns`). Therefore the aggregation step in orginal `score_hruns` is removed.

3. There are a few lines that needed edited to match the sample observed data being read into the df using `read.csv`. In `matilda` this won't be the case because the observed data will be retrieved from the criterion. 

4. There is now an `e` arg to set likelihood function decay.
____

Here is an example of using `bayes_wts` as the `score_function` argument in `score_hruns` with sample data:

```{r, message=FALSE}
# scoring h_runs

scored_data <- score_hruns_ed(h_result, criterion_co2_obs(), bayes_wts, e = 1.0)

print(scored_data)
```

With the data in `result_data` I can plot the decay of model scores as RMSE increases (as mean departure increases).

```{r}
library(ggplot2)
plot <- ggplot(data = scored_data, aes(x = RMSE, y = posterior_prob)) +
  geom_line(color = "blue")+
  geom_point(size = 2) +
  labs(y = "Likelihood (probability)")+
  theme_light()

ggsave("figure_output/example_scoring_curve.png",
       plot,
       device = "png",
       height = 12,
       width = 16,
       units = "cm",
       dpi = 300)
```

Figure shows model iterations as points along a line of decreasing score as the average model departure from observations increases (as RMSE increases). The run with the highest score re in this example is `run_zero` -- or a run that is identical to the observed data set and therefore has RMSE = 0.0.

____

Experimenting with other ideas:

It is also possible to edit the function to use a normal distribution of the observed data as the prior -- this would give higher weight to models that are closer to the distribution of the observed data. Assuming the observed data are are normally distributed. 

Function using Gaussian distribution:

```{r}
bayes_wts_norm_prior <- function(x) {
  
  # split the x data frame by model run_number 
  split_list = split(x, x$run_number)
  
  # for each of the dfs in the split_list compute RMSE using model predicted 
  # data and obs_data  
  rmse_vals = lapply(split_list, function(df) {
    RMSE_calc(x = df$value, y = df$value_obs)
  })
  
  # rbind the rmse_vals - makes it easier to complete subsequent steps
  rmse_bind <- do.call(rbind, rmse_vals)
  
  # Compute likelihood using normal distribution likelihood function.
  # This is the probability of observing the modeled data given the 
  # observed data.
  likelihood = exp(-0.5 * (rmse_bind) ^ 2)
  
  # Computing unnormalized posterior scores 
  # Compute prior using Gaussian distribution with mean set to the mean of the observed data
  prior_mean = mean(x$value_obs)
  prior_sd = sd(x$value_obs) # set the prior standard deviation to obs
  prior = dnorm(x = rmse_bind, mean = prior_mean, sd = prior_sd)
  posterior = likelihood * prior
  
  # Computes posterior probabilities - normalized posterior weights. 
  # Will sum to 1 and there for get significantly smaller as number 
  # of runs increases.
  posterior_probs = posterior / sum(posterior)
  
  # Create data frame of results - get run_numbers from the list where RMSE values
  # are computed (names of the split_list components)
  bayes_wts_result <- data.frame(RMSE = rmse_bind,
                                 posterior_vals = posterior,
                                 posterior_prob = posterior_probs,
                                 run_number = names(rmse_vals))
  
  return(bayes_wts_result)
}
```
